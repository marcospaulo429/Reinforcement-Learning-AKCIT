{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deepseek_test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import transformers\n",
    "from transformers.models.qwen2.modeling_qwen2 import Qwen2ForCausalLM\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleciona um modelo que já utiliza tokens de pensamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testa o modelo com um problema simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized prompt:\n",
      "<｜begin▁of▁sentence｜><｜begin▁of▁sentence｜><｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 15 multiplied by 7?\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "decoded_tokens = tokenizer.decode(inputs.input_ids[0])\n",
    "print(\"\\nTokenized prompt:\")\n",
    "print(decoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
      "First, I need to calculate 15 multiplied by 7.\n",
      "\n",
      "To do this, I can break down the multiplication into simpler parts. I'll start by multiplying 10 by 7, which gives me 70.\n",
      "\n",
      "Next, I'll multiply 5 by 7, resulting in 35.\n",
      "\n",
      "Finally, I'll add the two results together: 70 plus 35 equals 105.\n",
      "\n",
      "Therefore, 15 multiplied by 7 equals 105.\n",
      "</think>\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "To find the product of 15 and 7, follow these simple steps:\n",
      "\n",
      "1. **Multiply 10 by 7:**\n",
      "   \n",
      "   \\[\n",
      "   10 \\times 7 = 70\n",
      "   \\]\n",
      "\n",
      "2. **Multiply 5 by 7:**\n",
      "   \n",
      "   \\[\n",
      "   5 \\times 7 = 35\n",
      "   \\]\n",
      "\n",
      "3. **Add the two results together:**\n",
      "   \n",
      "   \\[\n",
      "   70 + 35 = 105\n",
      "   \\]\n",
      "\n",
      "Therefore, \n",
      "\n",
      "\\[\n",
      "15 \\times 7 = \\boxed{105}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "# Generate the response\n",
    "outputs = model.generate(\n",
    "    inputs.input_ids.to(model.device),\n",
    "    max_length=1000,\n",
    "    temperature=0.6,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "\n",
    "# Decode the generated tokens\n",
    "decoded_output = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes com o espaço de representação do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes decodificando embeddings sem passar pelo corpo do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_next_tokens(logits, top_k=5, bottom_k=5):\n",
    "    # Calculate probabilities over full vocabulary\n",
    "    probs = torch.softmax(logits[0][-1], dim=-1)\n",
    "    \n",
    "    # Get the top 10 most likely tokens and bottom 5 least likely tokens\n",
    "    top_probs, top_indices = probs.topk(k=top_k)\n",
    "    bottom_probs, bottom_indices = probs.topk(k=bottom_k, largest=False)\n",
    "    \n",
    "    top_logits = logits[0][-1][top_indices]\n",
    "    bottom_logits = logits[0][-1][bottom_indices]\n",
    "\n",
    "    # Decode back to text\n",
    "    top_tokens = [tokenizer.decode(idx) for idx in top_indices]\n",
    "    bottom_tokens = [tokenizer.decode(idx) for idx in bottom_indices]\n",
    "\n",
    "    print(f\"Top {top_k} most likely tokens when decoding embedding):\")\n",
    "    for i, (token, prob, logit) in enumerate(zip(top_tokens, top_probs, top_logits), 1):\n",
    "        print(f\"{i}. {token} (prob: {prob.item():.3f}, logit: {logit.item():.3f})\")\n",
    "        \n",
    "    print(f\"\\nBottom {bottom_k} least likely tokens:\")\n",
    "    for i, (token, prob, logit) in enumerate(zip(bottom_tokens, bottom_probs, bottom_logits), 1):\n",
    "        print(f\"{i}. {token} (prob: {prob.item():.3f}, logit: {logit.item():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aritmética no espaço de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most likely tokens when decoding embedding):\n",
      "1. king (prob: 0.000, logit: 2.207)\n",
      "2. woman (prob: 0.000, logit: 1.554)\n",
      "3. ,…\n",
      "\n",
      " (prob: 0.000, logit: 1.253)\n",
      "4. .${ (prob: 0.000, logit: 1.254)\n",
      "5. ?): (prob: 0.000, logit: 1.253)\n",
      "\n",
      "Bottom 5 least likely tokens:\n",
      "1.   (prob: 0.000, logit: -1.043)\n",
      "2. man (prob: 0.000, logit: -0.969)\n",
      "3. , (prob: 0.000, logit: -0.977)\n",
      "4.  ( (prob: 0.000, logit: -0.924)\n",
      "5. - (prob: 0.000, logit: -0.817)\n"
     ]
    }
   ],
   "source": [
    "# Get the token ID\n",
    "e1 = model.get_input_embeddings().weight[tokenizer.encode(\"king\", add_special_tokens=False)[0]]\n",
    "e2 = model.get_input_embeddings().weight[tokenizer.encode(\"man\", add_special_tokens=False)[0]]\n",
    "e3 = model.get_input_embeddings().weight[tokenizer.encode(\"woman\", add_special_tokens=False)[0]]\n",
    "logits = model.lm_head(((e1 - e2) + e3).reshape(1, 1, -1))  # deveria ser \"queen\"?\n",
    "print_top_next_tokens(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings da última camada correspondem aos embeddings da primeira camada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most likely tokens when decoding embedding):\n",
      "1. king (prob: 0.000, logit: 1.930)\n",
      "2. King (prob: 0.000, logit: 0.729)\n",
      "3.  king (prob: 0.000, logit: 0.686)\n",
      "4. kers (prob: 0.000, logit: 0.679)\n",
      "5. bidden (prob: 0.000, logit: 0.617)\n",
      "\n",
      "Bottom 5 least likely tokens:\n",
      "1. , (prob: 0.000, logit: -0.453)\n",
      "2.   (prob: 0.000, logit: -0.456)\n",
      "3.  ( (prob: 0.000, logit: -0.432)\n",
      "4. - (prob: 0.000, logit: -0.357)\n",
      "5. . (prob: 0.000, logit: -0.345)\n"
     ]
    }
   ],
   "source": [
    "# Get the token ID\n",
    "embedding = model.get_input_embeddings().weight[tokenizer.encode(\"king\", add_special_tokens=False)[0]]\n",
    "logits = model.lm_head(embedding.reshape(1, 1, -1))\n",
    "print_top_next_tokens(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most likely tokens when decoding embedding):\n",
      "1. \".. (prob: 0.000, logit: 0.864)\n",
      "2. ,…\n",
      "\n",
      " (prob: 0.000, logit: 0.830)\n",
      "3. )?. (prob: 0.000, logit: 0.832)\n",
      "4. ?): (prob: 0.000, logit: 0.830)\n",
      "5. ?,\n",
      " (prob: 0.000, logit: 0.819)\n",
      "\n",
      "Bottom 5 least likely tokens:\n",
      "1.   (prob: 0.000, logit: -0.786)\n",
      "2.  ( (prob: 0.000, logit: -0.692)\n",
      "3. , (prob: 0.000, logit: -0.700)\n",
      "4. . (prob: 0.000, logit: -0.585)\n",
      "5. - (prob: 0.000, logit: -0.552)\n"
     ]
    }
   ],
   "source": [
    "# Get the token ID\n",
    "embedding = model.get_input_embeddings().weight[tokenizer.encode(\"</think>\", add_special_tokens=False)[0]]\n",
    "logits = model.lm_head(embedding.reshape(1, 1, -1))\n",
    "print_top_next_tokens(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pega os logits do token `</think>` na última camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most likely tokens when decoding embedding):\n",
      "1. </think> (prob: 1.000, logit: 25.750)\n",
      "2. </ (prob: 0.000, logit: 15.953)\n",
      "3. Alternatively (prob: 0.000, logit: 13.242)\n",
      "4.   \n",
      " (prob: 0.000, logit: 12.602)\n",
      "5. ####\n",
      " (prob: 0.000, logit: 12.523)\n",
      "\n",
      "Bottom 5 least likely tokens:\n",
      "1. \" (prob: 0.000, logit: 4.086)\n",
      "2. ! (prob: 0.000, logit: 1.679)\n",
      "3. # (prob: 0.000, logit: 7.598)\n",
      "4. % (prob: 0.000, logit: 3.184)\n",
      "5. $ (prob: 0.000, logit: 2.434)\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"<｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
    "To solve 15 multiplied by 7, I can start by multiplying 10 by 7, which equals 70. Then, I'll multiply 5 by 7, resulting in 35. Adding these two products together, 70 plus 35, gives me the final answer of 105.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Get model outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "# Get logits from output\n",
    "logits1 = outputs.logits\n",
    "hidden_state = outputs.hidden_states[-1]\n",
    "print_top_next_tokens(logits1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between logits: 0.0848\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between logits and logits1\n",
    "cos_sim = torch.nn.functional.cosine_similarity(logits[0][-1].view(1,-1), logits1[0][-1].view(1,-1))\n",
    "print(f\"Cosine similarity between logits: {cos_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between embeddings: 0.0773\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between embeddings and the hidden state\n",
    "cos_sim = torch.nn.functional.cosine_similarity(embedding.view(1,-1), hidden_state[0][-1].view(1,-1))\n",
    "print(f\"Cosine similarity between embeddings: {cos_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função `generate` modificada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate padrão (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: <｜begin▁of▁sentence｜><｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
      "\n",
      "To solve 15 multiplied by 7, I start by breaking down the number 15 into 10 and 5. Multiplying 10 by 7 gives me 70, and multiplying 5 by 7 results in 35. Finally, adding these two products together, 70 and 35, gives the final result of 105.\n",
      "</think>\n",
      "\n",
      "To find the product of 15 multiplied by 7, follow these simple steps:\n",
      "\n",
      "### Step 1: Break Down the Numbers\n",
      "Break down 15 into its tens and ones place:\n",
      "- 15 = 10 + 5\n",
      "\n",
      "### Step 2: Multiply Each Part by 7\n",
      "- Multiply the tens place: \\( 10 \\times 7 = 70 \\)\n",
      "- Multiply the ones place: \\( 5 \\times 7 = 35 \\)\n",
      "\n",
      "### Step 3: Add the Results Together\n",
      "- Add the two products: \\( 70 + 35 = 105 \\)\n",
      "\n",
      "### Final Answer\n",
      "\\[\n",
      "\\boxed{105}\n",
      "\\]<｜end▁of▁sentence｜>"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, prompt, max_length=500, temperature=0.6):\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    \n",
    "    # Get initial embeddings\n",
    "    with torch.no_grad():\n",
    "        inputs_embeds = model.model.embed_tokens(input_ids)\n",
    "        \n",
    "    # Keep track of generated tokens for decoding\n",
    "    generated_ids = input_ids.clone()\n",
    "    \n",
    "    # Generate tokens auto-regressively\n",
    "    for _ in range(max_length):\n",
    "        # Get model outputs using accumulated embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model(inputs_embeds=inputs_embeds)\n",
    "            logits = model.lm_head(outputs[0])\n",
    "            \n",
    "        # Get logits for next token prediction\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        \n",
    "        # Apply temperature scaling\n",
    "        next_token_logits = next_token_logits / temperature\n",
    "        \n",
    "        # Get probabilities\n",
    "        probs = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "        \n",
    "        # Sample next token\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        \n",
    "        # Print the generated token\n",
    "        print(tokenizer.decode(next_token[0]), end='', flush=True)\n",
    "        \n",
    "        # Get embedding for next token\n",
    "        with torch.no_grad():\n",
    "            next_embed = model.model.embed_tokens(next_token)\n",
    "            \n",
    "        # Concatenate next embed\n",
    "        inputs_embeds = torch.cat([inputs_embeds, next_embed], dim=1)\n",
    "        \n",
    "        # Update generated ids for final decoding\n",
    "        generated_ids = torch.cat([generated_ids, next_token], dim=1)\n",
    "        \n",
    "        # Check if EOS token is generated\n",
    "        if next_token[0].item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    # Decode the generated tokens\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Test the generation\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"What is 15 multiplied by 7?\"}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False\n",
    ")\n",
    "print(f\"\\nPrompt: {prompt}\")\n",
    "generated = generate_text(model, tokenizer, prompt, temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate utilizando o espaço latente dentro dos tokens `<think/>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 1])\n",
      "<latent>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "的的的的的。。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "。。。。。。。！！！！！！!!。。。。。技巧方法方法方法地解决算！了啦！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！</latent>\n",
      "</latent>\n",
      "嗯，今天老师布置了一个数学题，让我算一下15乘以7是多少。刚开始看到这个题目的时候，我觉得挺简单的，但还是有点紧张，怕自己算错了。不过没关系，我慢慢来，仔细想一想。\n",
      "\n",
      "首先，我得回忆一下乘法的基本知识。乘法就是求几个相同数相加的总和，对吧？比如说，15乘以7，就是15加上自己6次，也就是15+15+15+15+15+15+15。嗯，这样算的话，我得算出这个总和是多少。\n",
      "\n",
      "不过，这样算起来可能有点麻烦，而且容易出错。我想，有没有什么简便的方法呢？比如说，分解因数或者找规律。比如说，15乘以7，我可以把15拆成10加5，然后分别乘以7，再把结果加起来。这样是不是更简单呢？\n",
      "\n",
      "好，我来试试看。首先，10乘以7等于70，然后5乘以7等于35。接下来，我把这两个结果加起来，70加35等于105。所以，15乘以7的结果应该是105。\n",
      "\n",
      "不过，我还是有点担心自己是不是哪里算错了。为了确认一下，我可以换一种方法来验证一下。比如说，我可以使用竖式乘法来计算。先把15写下来，然后乘以7，从个位开始乘起。\n",
      "\n",
      "首先，5乘以7等于35，写下5，进位3。然后，1乘以7等于7，加上进位的3，等于10。所以，结果就是105。嗯，和之前的结果一致，看来是对的。\n",
      "\n",
      "或者，我可以使用分配律来计算。比如说，15乘以7等于（10+5）乘以7，也就是10乘以7加上5乘以7，结果也是70加35等于105。这样看来，不管用什么方法，结果都是105，所以应该是正确的。\n",
      "\n",
      "不过，我还是有点好奇，有没有其他的方法可以用来验证这个结果。比如说，我可以使用计算器来计算，或者用其他数学技巧来确认。不过，现在手头没有计算器，只能依靠自己的计算能力了。\n",
      "\n",
      "再想想，15乘以7其实可以看作是15乘以7等于105，对吗？因为15乘以7等于105，所以这个结果是对的。嗯，看来我的计算是正确的，没有问题。\n",
      "\n",
      "总结一下，15乘以7等于105，这个结果可以通过多种方法验证，包括分解因数、竖式计算、分配律等，都得到了同样的结果。所以，我确定这个答案是正确的。\n",
      "</think>\n",
      "\n",
      "15乘以7等于105。\n",
      "\n",
      "步骤解释：\n",
      "1. ��15分解为10和5。\n",
      "2. 分别计算10乘以7等于70，5乘以7等于35。\n",
      "3. ��70和35相加，得到105。\n",
      "\n",
      "所以，15 × 7 = 105。<｜end▁of▁sentence｜>"
     ]
    }
   ],
   "source": [
    "def generate_text_latent(model, tokenizer, prompt, max_length=1000, max_thinking_tokens=100):\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    \n",
    "    # Track latent state\n",
    "    # Scan input ids for think tags\n",
    "    thinking_tokens = max_thinking_tokens\n",
    "    think_start = tokenizer.encode(\"<think>\", add_special_tokens=False)[0]\n",
    "    think_end = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "    think_count = 0\n",
    "    for token_id in input_ids[0]:\n",
    "        if token_id == think_start:\n",
    "            think_count += 1\n",
    "        elif token_id == think_end:\n",
    "            think_count -= 1\n",
    "    latent = think_count > 0  # True if there's an unclosed think tag\n",
    "    if latent:\n",
    "        print(input_ids.shape)\n",
    "        print(torch.tensor([[think_start]]).shape)\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[think_start]]).to(model.device)], dim=1)\n",
    "        print(\"<latent>\", end='', flush=True)\n",
    "    else:\n",
    "        input_ids = torch.cat([input_ids, torch.tensor([[think_end]]).to(model.device)], dim=1)\n",
    "        print(\"</latent>\", end='', flush=True)\n",
    "\n",
    "    # Keep track of generated tokens for decoding\n",
    "    generated_ids = input_ids.clone()\n",
    "\n",
    "    # Get initial embeddings\n",
    "    with torch.no_grad():\n",
    "        inputs_embeds = model.model.embed_tokens(input_ids)\n",
    "\n",
    "    # Generate tokens auto-regressively\n",
    "    for _ in range(max_length):\n",
    "        # Get model outputs using accumulated embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model(inputs_embeds=inputs_embeds)\n",
    "            logits = model.lm_head(outputs[0])\n",
    "        next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
    "\n",
    "        # Update latent state based on token\n",
    "        if latent:\n",
    "            thinking_tokens -= 1\n",
    "            if next_token[0].item() != think_end and thinking_tokens > 0:\n",
    "                # Still thinking\n",
    "                next_token_hidden = outputs[0][:, -1, :]\n",
    "                next_embed = next_token_hidden.unsqueeze(1)\n",
    "                # inputs_embeds = inputs_embeds[:, :-1, :]  # Uncomment this to replace the last token instead of appending it to the sequence\n",
    "            else:\n",
    "                # Exit latent space\n",
    "                latent = False\n",
    "                next_token = tokenizer(\"\\n</latent>\\n\", add_special_tokens=False, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "                next_embed = model.model.embed_tokens(next_token)\n",
    "                print(\"</latent>\", end='', flush=True)\n",
    "                thinking_tokens = max_thinking_tokens\n",
    "        else:\n",
    "            if next_token[0] == think_start:\n",
    "                # Start thinking\n",
    "                latent = True\n",
    "                print(\"<latent>\", end='', flush=True)\n",
    "            with torch.no_grad():\n",
    "                next_embed = model.model.embed_tokens(next_token)\n",
    "\n",
    "        # Concatenate next embed\n",
    "        inputs_embeds = torch.cat([inputs_embeds, next_embed], dim=1)\n",
    "        # Update generated ids for final decoding\n",
    "        generated_ids = torch.cat([generated_ids, next_token], dim=1)\n",
    "        \n",
    "        # Print the generated token\n",
    "        print(tokenizer.decode(next_token[0]), end='', flush=True)\n",
    "\n",
    "        # Check if EOS token is generated\n",
    "        if tokenizer.eos_token_id in next_token[0]:\n",
    "            break\n",
    "\n",
    "    # Decode the generated tokens\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Test the generation\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"What is 15 multiplied by 7?\"}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False\n",
    ")\n",
    "print(prompt, end='', flush=True)\n",
    "generated = generate_text_latent(model, tokenizer, prompt, max_thinking_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapas de atenção (até agora não funciona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
      "<latent>!!!!!"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryan/miniconda3/envs/llm/lib/python3.9/site-packages/seaborn/matrix.py:202: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = np.nanmin(calc_data)\n",
      "/home/bryan/miniconda3/envs/llm/lib/python3.9/site-packages/seaborn/matrix.py:207: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = np.nanmax(calc_data)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_text_latent_with_attention(model, tokenizer, prompt, max_length=100, max_thinking_tokens=100):\n",
    "    # Encode the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    \n",
    "    # Get initial embeddings\n",
    "    with torch.no_grad():\n",
    "        inputs_embeds = model.model.embed_tokens(input_ids)\n",
    "        \n",
    "    # Keep track of generated tokens for decoding\n",
    "    generated_ids = input_ids.clone()\n",
    "    \n",
    "    # Track latent state\n",
    "    # Scan input ids for think tags\n",
    "    think_start = tokenizer.encode(\"<think>\", add_special_tokens=False)[0]\n",
    "    think_end = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "    think_count = 0\n",
    "    for token_id in input_ids[0]:\n",
    "        if token_id == think_start:\n",
    "            think_count += 1\n",
    "        elif token_id == think_end:\n",
    "            think_count -= 1\n",
    "    latent = think_count > 0  # True if there's an unclosed think tag\n",
    "    print(\"<latent>\" if latent else \"</latent>\", end='', flush=True)\n",
    "\n",
    "    thinking_tokens = max_thinking_tokens\n",
    "    all_attention_weights = []\n",
    "    all_tokens = []\n",
    "\n",
    "    # Generate tokens auto-regressively\n",
    "    for _ in range(max_length):\n",
    "        # Get model outputs using accumulated embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model(inputs_embeds=inputs_embeds, output_attentions=True)  # modelo para de funcionar quando usa output_attentions\n",
    "            logits = model.lm_head(outputs[0])\n",
    "        next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
    "\n",
    "        # Store attention weights from last layer\n",
    "        attention_weights = outputs.attentions[-1]  # Shape: [batch, num_heads, seq_len, seq_len]\n",
    "        all_attention_weights.append(attention_weights)\n",
    "\n",
    "        # Update latent state based on token\n",
    "        if latent:\n",
    "            thinking_tokens -= 1\n",
    "            if next_token[0].item() != think_end and thinking_tokens > 0:\n",
    "                next_token_hidden = outputs[0][:, -1, :]\n",
    "                next_embed = next_token_hidden.unsqueeze(1)\n",
    "            else:\n",
    "                latent = False\n",
    "                next_token = tokenizer(\"\\n</think>\\n\", add_special_tokens=False, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "                next_embed = model.model.embed_tokens(next_token)\n",
    "                print(\"</latent>\", end='', flush=True)\n",
    "                thinking_tokens = max_thinking_tokens\n",
    "        else:\n",
    "            if next_token[0] == think_start:\n",
    "                latent = True\n",
    "                print(\"<latent>\", end='', flush=True)\n",
    "            with torch.no_grad():\n",
    "                next_embed = model.model.embed_tokens(next_token)\n",
    "\n",
    "        # Concatenate next embed\n",
    "        inputs_embeds = torch.cat([inputs_embeds, next_embed], dim=1)\n",
    "        # Update generated ids for final decoding\n",
    "        generated_ids = torch.cat([generated_ids, next_token], dim=1)\n",
    "        \n",
    "        # Print the generated token\n",
    "        print(tokenizer.decode(next_token[0]), end='', flush=True)\n",
    "\n",
    "        # Store generated token\n",
    "        all_tokens.append(tokenizer.decode(next_token[0]))\n",
    "\n",
    "        # Check if EOS token is generated\n",
    "        if tokenizer.eos_token_id in next_token[0]:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    # Decode the generated tokens\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text, all_attention_weights, all_tokens\n",
    "\n",
    "def plot_attention_map(attention_weights, tokens, layer_idx=-1, head_idx=0):\n",
    "    \"\"\"\n",
    "    Plot attention map for a specific layer and attention head\n",
    "    \n",
    "    Args:\n",
    "        attention_weights: List of attention tensors\n",
    "        tokens: List of token strings\n",
    "        layer_idx: Which transformer layer to visualize (-1 for last layer)\n",
    "        head_idx: Which attention head to visualize\n",
    "    \"\"\"\n",
    "    # Convert attention weights to numpy array\n",
    "    # Get sequence length for each attention matrix\n",
    "    seq_lens = [w.size(-1) for w in attention_weights]\n",
    "    min_seq_len = min(seq_lens)\n",
    "    \n",
    "    # Truncate each attention matrix to minimum sequence length\n",
    "    attn_matrix = torch.cat([w[0, head_idx, -1:, :min_seq_len] for w in attention_weights], dim=0)\n",
    "    attn_matrix = attn_matrix.cpu().numpy()\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        attn_matrix,\n",
    "        xticklabels=tokens[:min_seq_len],\n",
    "        yticklabels=tokens[-len(attn_matrix):],\n",
    "        cmap='viridis',\n",
    "        cbar_kws={'label': 'Attention Weight'}\n",
    "    )\n",
    "    \n",
    "    plt.title(f'Attention Map (Layer {layer_idx}, Head {head_idx})')\n",
    "    plt.xlabel('Input Tokens')\n",
    "    plt.ylabel('Output Tokens')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test the generation\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"What is 15 multiplied by 7?\"}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False\n",
    ") # + \"Chinese Dangerous wishes</think>\"\n",
    "print(prompt, end='', flush=True)\n",
    "generated, attention_weights, tokens = generate_text_latent_with_attention(\n",
    "    model, tokenizer, prompt, max_thinking_tokens=10\n",
    ")\n",
    "\n",
    "# Plot attention map for the last layer, first head\n",
    "plot_attention_map(attention_weights, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(151667, 1536)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.custom_qwen.latent_modeling import LatentModelForCausalLM\n",
    "\n",
    "model = LatentModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_tokens(\"<latent>\")\n",
    "tokenizer.add_tokens(\"</latent>\")\n",
    "\n",
    "model.config.start_think_token_id = tokenizer.convert_tokens_to_ids(\"<think>\")\n",
    "model.config.end_think_token_id = tokenizer.convert_tokens_to_ids(\"</think>\")\n",
    "model.config.start_latent_token_id = tokenizer.convert_tokens_to_ids(\"<latent>\")\n",
    "model.config.end_latent_token_id = tokenizer.convert_tokens_to_ids(\"</latent>\")\n",
    "model.config.auto_map = {\n",
    "    \"AutoModelForCausalLM\": \"latent_modeling.LatentModelForCausalLM\",\n",
    "    \"AutoModel\": \"latent_modeling.LatentModelForCausalLM\"\n",
    "}\n",
    "model.config.head_dim = model.config.hidden_size // model.config.num_attention_heads\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('custom_qwen/tokenizer_config.json',\n",
       " 'custom_qwen/special_tokens_map.json',\n",
       " 'custom_qwen/tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"custom_qwen\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentModelForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151667, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151667, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    \"custom_qwen\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    \"custom_qwen\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available arguments for model.generate:\n",
      "input_ids: None\n",
      "attention_mask: None\n",
      "max_length: 50\n",
      "num_return_sequences: 1\n",
      "temperature: 1.0\n",
      "top_k: 50\n",
      "top_p: 1.0\n",
      "repetition_penalty: 1.0\n",
      "max_thinking_tokens: 10\n",
      "kwargs: <class 'inspect._empty'>\n"
     ]
    }
   ],
   "source": [
    "# Get the signature of the generate method\n",
    "import inspect\n",
    "\n",
    "generate_signature = inspect.signature(model.generate)\n",
    "print(\"Available arguments for model.generate:\")\n",
    "for param_name, param in generate_signature.parameters.items():\n",
    "    print(f\"{param_name}: {param.default}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜User｜>What is 15 multiplied by 7?<｜Assistant｜><think>\n",
      "To100000</think>  here? No. Wait, number of birds per Moon. For more information, visit. How many Birds per Year? No. 551. I have a question.\n",
      "\n",
      "Alright, so I have\n"
     ]
    }
   ],
   "source": [
    "input_text = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"What is 15 multiplied by 7?\"}],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False\n",
    ")\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(input_ids=input_ids.to(model.device))\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
    "MODEL=\"../custom_qwen\"\n",
    "MODEL_ARGS=\"pretrained=$MODEL,dtype=bfloat16,max_model_length=32768,gpu_memory_utilisation=0.9\"\n",
    "OUTPUT_DIR=data/evals/$MODEL\n",
    "\n",
    "# MATH-500\n",
    "TASK=math_500\n",
    "lighteval vllm $MODEL_ARGS \"custom|$TASK|0|0\" \\\n",
    "    --custom-tasks src/open_r1/evaluate.py \\\n",
    "    --use-chat-template \\\n",
    "    --output-dir $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, the user greeted me with \"Hello world.\" It sounds like they're just starting a conversation.\n",
      "\n",
      "I should respond in a friendly and open manner to set a positive tone.\n",
      "\n",
      "Maybe I can offer to help out with whatever they need.\n",
      "\n",
      "Keeping it simple and welcoming is probably the best approach.\n",
      "</think>\n",
      "\n",
      "Hello! It's great to have you here. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create client pointing to local server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:18080/v1\",\n",
    "    api_key=\"not-needed\" # The API key is not actually used but required\n",
    ")\n",
    "\n",
    "# Test with a simple completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"custom_qwen\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello world\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
