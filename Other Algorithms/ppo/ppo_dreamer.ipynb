{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from dm_control import suite\n",
    "from replay_buffer import ReplayBuffer\n",
    "from general_algo import collect_replay_buffer\n",
    "from dm_control.suite.wrappers import pixels\n",
    "from auxiliares import training_device\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "\n",
    "def reparameterize(z_mean, z_log_var):\n",
    "    std = torch.exp(0.5 * z_log_var)\n",
    "    eps = torch.randn_like(std)\n",
    "    return z_mean + eps * std\n",
    "\n",
    "# Encoder com mais camadas convolucionais para maior poder representacional\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim, in_channels=1,hidden_units = 32):  \n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_units, kernel_size=4, stride=2, padding=1)   # -> (batch, 64, 42, 42)\n",
    "        self.conv2 = nn.Conv2d(hidden_units, hidden_units*2, kernel_size=4, stride=2, padding=1)            # -> (batch, 128, 21, 21)\n",
    "        self.conv3 = nn.Conv2d(hidden_units*2, hidden_units*4, kernel_size=4, stride=2, padding=1)           # -> (batch, 256, 10, 10)\n",
    "        \n",
    "        self.flatten_dim = hidden_units*4 * 10 * 10  # Tamanho do vetor achatado após as convoluções\n",
    "        self.fc_mean = nn.Linear(self.flatten_dim, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(self.flatten_dim, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)  # Achata para (batch, flatten_dim)\n",
    "        z_mean = self.fc_mean(x)\n",
    "        z_log_var = self.fc_log_var(x)\n",
    "        return z_mean, z_log_var\n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, out_channels=1, hidden_units=32):  # Alterei o out_channels para 3 para imagens RGB\n",
    "        super(CNNDecoder, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.fc = nn.Linear(latent_dim, hidden_units*4 * 10 * 10)  # Mapeia o vetor latente para uma representação plana\n",
    "        self.deconv1 = nn.ConvTranspose2d(hidden_units*4, hidden_units*2, kernel_size=4, stride=2, padding=1, output_padding=1)  \n",
    "        self.deconv2 = nn.ConvTranspose2d(hidden_units*2, hidden_units, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "        self.deconv3 = nn.ConvTranspose2d(hidden_units, out_channels, kernel_size=4, stride=2, padding=1, output_padding=0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(x.size(0), (self.hidden_units)*4, 10, 10)  # Reorganiza para (batch, 256, 10, 10)\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = torch.tanh(self.deconv3(x))  # Sigmoid para valores entre 0 e 1\n",
    "        return x\n",
    "\n",
    "\n",
    "# VAE combinando o Encoder e o Decoder com CNNs mais complexas\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim, in_channels=1, hidden_units=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = CNNEncoder(latent_dim, in_channels,hidden_units=hidden_units)\n",
    "        self.decoder = CNNDecoder(latent_dim, out_channels=in_channels, hidden_units=hidden_units)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z_mean, z_log_var = self.encoder(x)\n",
    "        z = reparameterize(z_mean, z_log_var)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, z_mean, z_log_var\n",
    "\n",
    "\n",
    "def vae_loss_fn(encoder_inputs, vae_outputs, z_mean, z_log_var):\n",
    "    \n",
    "    # Cálculo do erro de reconstrução (MSE médio por amostra)\n",
    "    reconstruction_loss = F.mse_loss(vae_outputs, encoder_inputs, reduction='sum') / encoder_inputs.size(0)\n",
    "    \n",
    "    # Cálculo da divergência KL\n",
    "    # KL = -0.5 * mean(1 + log_var - z_mean^2 - exp(log_var))\n",
    "    kl_loss = -0.2 * torch.mean(1 + z_log_var - z_mean.pow(2) - torch.exp(z_log_var))\n",
    "    \n",
    "    return reconstruction_loss + kl_loss\n",
    "\n",
    "device = training_device()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
